## Goal
The goal of the lab1 is to guide you to bring your own model to the sample configurations and run your model on deepstream.

## Steps

### Step 1: Create the deepstream enviroment
1. google "Ngc nvidia"
2. Open the terminal
```
docker run --gpus all -it --rm --net=host --privileged -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$DISPLAY -w /opt/nvidia/deepstream/deepstream-6.1 nvcr.io/nvidia/deepstream:6.1-samples
```
3. cd to the deepstream-app folder
```
cd samples/configs/deepstream-app
```
4. Install needed tool
```
apt-get update
apt-get install wget
apt-get install unzip
apt-get install vim
```

### Step 2: Download the files needed (model and parser library)

1. Download the files needed including model.onnx, label.txt, parser library, and config files for bringing your own model on deepstream 
```
wget https://leannazdeepstream.blob.core.windows.net/learningseries/MyCustomThings.zip
```

2. Unzip the folder you just downloaded
```
unzip MyCustomThings
```

3. cd to the folder you just unzipped
```
cd MyCustomThings
```
4.  copy to the config file to the deepstream-app folder for convinience
```
cp config_infer_custom_vision.txt /opt/nvidia/deepstream/deepstream-6.1/samples/configs/deepstream-app/
```

5. Go to the deepstream-app folder 
```
cd ..
```

### Step 3: Edit sample configurations to modify video source and specify the location of the config file
1. Edit the sample configurations and streams
```
vim source4_1080p_dec_infer-resnet_tracker_sgie_tiled_display_int8.txt
```
2.  Config the sample configurations

- Set the property `enable` to `0` under [tiled-display]
    ```
    [tiled-display]
    enable=0
    ```
- Modify the `uri` under [source0] 
    ```
    [source0]
    enable=1
    #Type - 1=CameraV4L2 2=URI 3=MultiURI 4=RTSP
    type=3
    uri=file://MyCustomThings/IMG_0695.mp4
    ```

- Set the property `enable` to `0` under [sink0]
    ```
    [sink0] 
    enable=0
    ```

- Set the property `enable` to `1` under [sink1]
    ```
    [sink1] 
    enable=1
    ```
- Specify the location of the config file. Set `config-file` to `config_infer_custom_vision.txt`
    ```
    [primary-gie] 
    config-file=config_infer_custom_vision.txt
    ```

### Step 4: Initiate the deepstream pipeline
1. Execute the command to initiate the deepstream pipeline
```
deepstream-app -c source4_1080p_dec_infer-resnet_tracker_sgie_tiled_display_int8.txt
```

### Step 5: View the video file
1. Copy the file you generated out to your host
    
ex:
```
docker cp b1318da02df7:/opt/nvidia/deepstream/deepstream-6.1/samples/configs/deepstream-app/out.mp4 out_new.mp4
```

2.  Scp the file to your jump server
ex:
```
scp leann@172.23.30.55:/home/leann/out_new.mp4 out_new.mp4
```

## Links
1. [Sample Configurations and Streams](https://docs.nvidia.com/metropolis/deepstream/5.0/dev-guide/index.html#page/DeepStream_Development_Guide/deepstream_Sample_configs_and_Streams.html)
2. [Configuration Groups](https://docs.nvidia.com/metropolis/deepstream/5.0/dev-guide/index.html#page/DeepStream_Development_Guide/deepstream_ref_app_deepstream_app.html#wwpID0E02D0HA)
3. [Containerize your own model generated by Custom Vision website as an edge ai module and run on deepstream](https://github.com/leannhuang/cv-model-with-deepstream-on-kubernetes)

## Extended Learning
1. Set up the output as RTSP and view the RTSP stream in the jump server
2. Containerize what you did and push to dockerhub. Docker pull your image to run on Azure HCI